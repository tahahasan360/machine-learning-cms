{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('data/aol/user-ct-test-collection-05.txt', sep=\"\\t\")\n",
    "training_queries = training_data.Query.dropna()\n",
    "training_tokens_freq = Counter(training_queries)\n",
    "\n",
    "testing_data = pd.read_csv('data/aol/user-ct-test-collection-04.txt', sep=\"\\t\")\n",
    "testing_queries = training_data.Query.dropna()\n",
    "testing_tokens_freq = Counter(training_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features\n",
    "def extract_features(token):\n",
    "    length = len(token)\n",
    "    digits = sum(c.isdigit() for c in token)\n",
    "    upper = sum(c.isupper() for c in token)\n",
    "    lower = sum(c.islower() for c in token)\n",
    "    special = sum(not c.isalnum() for c in token)\n",
    "    entropy = -sum((token.count(c)/len(token)) * np.log2(token.count(c)/len(token)) for c in set(token))\n",
    "    return [length, digits, upper, lower, special, entropy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "X_train = list(training_tokens_freq.keys())\n",
    "y_train = list(training_tokens_freq.values())\n",
    "X_test = list(testing_tokens_freq.keys())\n",
    "y_test = list(testing_tokens_freq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2,2))\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1080747     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.11227D+06    |proj g|=  7.77456D+05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    }
   ],
   "source": [
    "# class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "# class_weights_dict = {i : class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Train the model\n",
    "# model = LogisticRegression(class_weight=class_weights_dict)\n",
    "model = LogisticRegression(max_iter=2)\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9991651328559645\n",
      "F1 Score: 0.03571428571428571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1292519,     541],\n",
       "       [    539,      20]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = (model.predict_proba(X_test_vectorized)[:, 1] >= 0.94).astype(int)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"F1 Score:\", f1_score(y_test, predictions))\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Oracle import Oracle\n",
    "import pickle\n",
    "\n",
    "filename = 'models/logistic_regression.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
